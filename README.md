# NetworkIntrusionDetector
# 🤖 Prediction of Network Intrusions using Deep Reinforcement Learning

This project analyzes network traffic features and applies Deep Reinforcement Learning to predict **network intrusions** (Attacks) vs. **benign traffic**.

## 🚀 **Project Overview**

- **Goal:** Develop an intelligent agent that acts as a smart firewall, learning to classify network packets to support cybersecurity efforts.
- **Dataset Source:** [Network Intrusion Dataset (Kaggle)](https://www.kaggle.com/datasets/chethuhn/network-intrusion-dataset)
- **Model Used:** Deep Q-Network (DQN) Agent
- **Tools & Technologies:** Python, pandas, numpy, scikit-learn, Gymnasium, Stable-Baselines3

---

## 📁 **Dataset**

**Key Features:**

- **Dataset:** Network Intrusion Dataset (automatically downloaded via KaggleHub)
- **Data Type:** Benign traffic and various attack types (e.g., DDoS).
- **Features:** 78 different network flow features, including:
  - `Flow Duration`
  - `Total Fwd Packets`
  - `Total Backward Packets`
  - `Fwd Packet Length Max/Min/Mean`
  - `Flow IAT Mean/Std/Max/Min`
- **Target:** `Label` (classified as `BENIGN` (0) or `ATTACK` (1))

---

## 📂 **Project Structure**
```
NetworkIntrusionDetector/
│
├── data/                 # (GitIgnored) Holds raw, interim, and processed data
├── notebooks/            # Jupyter notebooks for exploration and step-by-step runs
│   ├── 01_data_preprocessing.ipynb
│   ├── 02_feature_scaling.ipynb
│   ├── 03_rl_environment.ipynb
│   └── 04_dqn_training.ipynb
│
├── src/                  # All Python source code
│   ├── data/
│   │   └── make_dataset.py       # Downloads, cleans, and splits data
│   ├── features/
│   │   └── build_features.py     # Scales features and saves scaler
│   ├── env/
│   │   └── intrusion_env.py      # Defines the custom `IntrusionEnv`
│   ├── models/
│   │   ├── train_agent.py        # Trains the DQN model
│   │   └── evaluate_agent.py     # Evaluates the model and saves plots
│   └── utils/
│       └── helpers.py            # Manages file paths
│
├── models/               # (GitIgnored) Saved models and scalers
│   ├── dqn_agent.zip
│   └── scaler.joblib
│
├── media/
│   └── plots/
│       └── confusion_matrix.png  # Saved evaluation plot
│
├── requirements.txt      # Python dependencies
├── README.md             # This file
└── .gitignore            # Files and folders to ignore
```

## 🔬 **Methodology**

1.  **Data Preparation:** Downloaded data via `kagglehub`, merged all CSVs, cleaned data, and performed balancing and sampling (`random_state=42`) to create 20k training and 20k test samples.
2.  **Feature Engineering:** Scaled all 78 features using `MinMaxScaler` and saved the scaler.
3.  **Environment:** Built a custom `IntrusionEnv` using `gymnasium`.
    -   **State:** A vector of 78 scaled network features.
    -   **Actions:** 2 discrete actions: 0 (ALLOW) or 1 (DENY).
    -   **Rewards:** A custom reward structure was defined:
        -   `+10`: Correctly DENYing an ATTACK.
        -   `+1`: Correctly ALLOWing BENIGN traffic.
        -   `-5`: Incorrectly DENYing BENIGN traffic (False Positive).
        -   `-10`: Incorrectly ALLOWing an ATTACK (False Negative).
4.  **Model Building:**
    -   Split data into training and testing sets.
    -   Trained a **DQN Agent** from `stable_baselines3` for 50,000 timesteps.
    -   Evaluated performance using **Accuracy**, **Classification Report**, and **Confusion Matrix**.

---

## 💾 **Model Output**

The trained model (`dqn_agent.zip`) and scaler (`scaler.joblib`) are generated by running the training scripts. They are saved to the `/models/` directory, which is listed in `.gitignore`.

*(To use the models, you must first run the training pipeline as described in the "How to Run" section.)*

---

## 📈 **Results**

-   **Accuracy:** 88.09%
-   **Classification Report:** The model is highly effective at identifying attacks (99% Recall) but is overly cautious, resulting in more false positives (77% Recall for Benign).

| | precision | recall | f1-score | support |
| :--- | :---: | :---: | :---: | :---: |
| **Benign (0)** | 0.99 | 0.77 | 0.87 | 10110 |
| **Attack (1)** | 0.81 | 0.99 | 0.89 | 9890 |
| **accuracy** | | | 0.88 | 20000 |

---

## 🏁 **Conclusion**

-   Successfully built a **DQN Reinforcement Learning agent** to act as a smart network firewall.
-   Gained hands-on experience in the **end-to-end RL pipeline**: from custom environment design to model training and evaluation.
-   Future work includes tuning the reward function to balance the trade-off between false positives and false negatives, and testing other agents like **PPO** or **A2C**.

---

## 👤 **Author**

**Ritam Santra**
- **GitHub:** [SantraRS](https://github.com/SantraRS)
- *(Feel free to add your Internship IDs or other info here)*

---

✨ *Feel free to fork, use, or extend this project for your reinforcement learning explorations!*
