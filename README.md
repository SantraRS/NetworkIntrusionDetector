# NetworkIntrusionDetector
# ğŸ¤– Prediction of Network Intrusions using Deep Reinforcement Learning

This project analyzes network traffic features and applies Deep Reinforcement Learning to predict **network intrusions** (Attacks) vs. **benign traffic**.

## ğŸš€ **Project Overview**

- **Goal:** Develop an intelligent agent that acts as a smart firewall, learning to classify network packets to support cybersecurity efforts.
- **Dataset Source:** [Network Intrusion Dataset (Kaggle)](https://www.kaggle.com/datasets/chethuhn/network-intrusion-dataset)
- **Model Used:** Deep Q-Network (DQN) Agent
- **Tools & Technologies:** Python, pandas, numpy, scikit-learn, Gymnasium, Stable-Baselines3

---

## ğŸ“ **Dataset**

**Key Features:**

- **Dataset:** Network Intrusion Dataset (automatically downloaded via KaggleHub)
- **Data Type:** Benign traffic and various attack types (e.g., DDoS).
- **Features:** 78 different network flow features, including:
  - `Flow Duration`
  - `Total Fwd Packets`
  - `Total Backward Packets`
  - `Fwd Packet Length Max/Min/Mean`
  - `Flow IAT Mean/Std/Max/Min`
- **Target:** `Label` (classified as `BENIGN` (0) or `ATTACK` (1))

---

## ğŸ“‚ **Project Structure**
```
NetworkIntrusionDetector/
â”‚
â”œâ”€â”€ data/                 # (GitIgnored) Holds raw, interim, and processed data
â”œâ”€â”€ notebooks/            # Jupyter notebooks for exploration and step-by-step runs
â”‚   â”œâ”€â”€ 01_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_feature_scaling.ipynb
â”‚   â”œâ”€â”€ 03_rl_environment.ipynb
â”‚   â””â”€â”€ 04_dqn_training.ipynb
â”‚
â”œâ”€â”€ src/                  # All Python source code
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ make_dataset.py       # Downloads, cleans, and splits data
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py     # Scales features and saves scaler
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â””â”€â”€ intrusion_env.py      # Defines the custom `IntrusionEnv`
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_agent.py        # Trains the DQN model
â”‚   â”‚   â””â”€â”€ evaluate_agent.py     # Evaluates the model and saves plots
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helpers.py            # Manages file paths
â”‚
â”œâ”€â”€ models/               # (GitIgnored) Saved models and scalers
â”‚   â”œâ”€â”€ dqn_agent.zip
â”‚   â””â”€â”€ scaler.joblib
â”‚
â”œâ”€â”€ media/
â”‚   â””â”€â”€ plots/
â”‚       â””â”€â”€ confusion_matrix.png  # Saved evaluation plot
â”‚
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # This file
â””â”€â”€ .gitignore            # Files and folders to ignore
```

## ğŸ”¬ **Methodology**

1.  **Data Preparation:** Downloaded data via `kagglehub`, merged all CSVs, cleaned data, and performed balancing and sampling (`random_state=42`) to create 20k training and 20k test samples.
2.  **Feature Engineering:** Scaled all 78 features using `MinMaxScaler` and saved the scaler.
3.  **Environment:** Built a custom `IntrusionEnv` using `gymnasium`.
    -   **State:** A vector of 78 scaled network features.
    -   **Actions:** 2 discrete actions: 0 (ALLOW) or 1 (DENY).
    -   **Rewards:** A custom reward structure was defined:
        -   `+10`: Correctly DENYing an ATTACK.
        -   `+1`: Correctly ALLOWing BENIGN traffic.
        -   `-5`: Incorrectly DENYing BENIGN traffic (False Positive).
        -   `-10`: Incorrectly ALLOWing an ATTACK (False Negative).
4.  **Model Building:**
    -   Split data into training and testing sets.
    -   Trained a **DQN Agent** from `stable_baselines3` for 50,000 timesteps.
    -   Evaluated performance using **Accuracy**, **Classification Report**, and **Confusion Matrix**.

---

## ğŸ’¾ **Model Output**

The trained model (`dqn_agent.zip`) and scaler (`scaler.joblib`) are generated by running the training scripts. They are saved to the `/models/` directory, which is listed in `.gitignore`.

*(To use the models, you must first run the training pipeline as described in the "How to Run" section.)*

---

## ğŸ“ˆ **Results**

-   **Accuracy:** 88.09%
-   **Classification Report:** The model is highly effective at identifying attacks (99% Recall) but is overly cautious, resulting in more false positives (77% Recall for Benign).

| | precision | recall | f1-score | support |
| :--- | :---: | :---: | :---: | :---: |
| **Benign (0)** | 0.99 | 0.77 | 0.87 | 10110 |
| **Attack (1)** | 0.81 | 0.99 | 0.89 | 9890 |
| **accuracy** | | | 0.88 | 20000 |

---

## ğŸ **Conclusion**

-   Successfully built a **DQN Reinforcement Learning agent** to act as a smart network firewall.
-   Gained hands-on experience in the **end-to-end RL pipeline**: from custom environment design to model training and evaluation.
-   Future work includes tuning the reward function to balance the trade-off between false positives and false negatives, and testing other agents like **PPO** or **A2C**.

---

## ğŸ‘¤ **Author**

**Ritam Santra**
- **GitHub:** [SantraRS](https://github.com/SantraRS)
- *(Feel free to add your Internship IDs or other info here)*

---

âœ¨ *Feel free to fork, use, or extend this project for your reinforcement learning explorations!*
